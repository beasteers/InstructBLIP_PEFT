# Copyright (c) 2022, salesforce.com, inc.
# All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause
# For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

model:
  arch: blip2_t5_instruct_qformer_lora_clsf
  model_type: flant5xl
  load_pretrained: True #pretrain from scratch
  freeze_vit: True
  lora_r: 16
  lora_alpha: 8
  lora_dropout: 0
  self_attention_qv_lora: False
  self_attention_output_lora: False
  ffn_lora: True
  qformer_crossattention_lora_q: True
  qformer_crossattention_lora_k: True
  qformer_crossattention_lora_v: True
  qformer_crossattention_lora_o: True
  # lora_r: 4
  # lora_alpha: 8
  # lora_dropout: 0
  # self_attention_qv_lora: False
  # self_attention_output_lora: False
  # ffn_lora: True
  # qformer_crossattention_lora_q: False
  # qformer_crossattention_lora_k: False
  # qformer_crossattention_lora_v: False
  # qformer_crossattention_lora_o: False
  qformer_cls_arch: dense
  qformer_num_classes: 37
  # qformer_video_input: True

  qformer_cls_labels:
  - (above ?a ?b)
  - (attached ?a ?b)
  - (behind ?a ?b)
  - (broken ?a)
  - (close ?a)
  - (closed ?a)
  - (deformed ?a)
  - (empty ?a)
  - (far ?a)
  - (fits ?a ?b)
  - (folded ?a)
  - (full ?a)
  - (has-hole ?a)
  - (high ?a)
  - (in ?a ?b)
  - (infront ?a ?b)
  - (is-bendable ?a)
  - (is-fluid ?a)
  - (is-holdable ?a)
  - (is-rigid ?a)
  - (is-spreadable ?a)
  - (is-tearable ?a)
  - (left ?a)
  - (low ?a)
  - (nextto ?a ?b)
  - (on ?a ?b)
  - (onsurface ?a)
  - (open ?a)
  - (right ?a)
  - (stacked ?a)
  - (stretched ?a)
  - (torn ?a)
  - (touching ?a ?b)
  - (twisted ?a)
  - (under ?a ?b)
  - (upright ?a)
  - (visible ?a)


datasets:
  s20bn:
    train_samples_portion: all
    splits:
      all:
        inner_buffer: 2
        include_detections: True
        qa_prompt:
          - describe_predicates
          - action_before_after
          - action_complete
          - yes_no_predicate
    #   train: 
    #   val: 
    #   test: 
    vis_processor:
      train:
        name: "blip2_image_train"
        image_size: 224
      eval:
        name: "blip_image_eval"
        image_size: 224
    text_processor:
      train:
        name: "instruct_blip_question"
      eval:
        name: "instruct_blip_question"

run:
  task: epic_kitchens
  # optimizer
  lr_sched: "linear_decay_lr"
  init_lr: 1e-4
  min_lr: 0
  warmup_lr: 5e-4
  warmup_steps: 0

  weight_decay: 0.05
  max_epoch: 20
  batch_size_train: 64
  accum_grad_iters: 1
  batch_size_eval: 16
  num_workers: 12

  # inference-specific
  max_len: 96
  min_len: 1
  num_beams: 16
  num_ans_candidates: 16
  inference_method: "rank"

  seed: 42
  output_dir: "output/results/s20bn/s20bn_1"

  amp: True
  resume_ckpt_path: null

  evaluate: false
  initial_evaluate: false
  train_splits: ["train"]
  valid_splits: ["val"]
  test_splits: ["test"]
  # disable_early_stopping: true

  device: "cuda"
  world_size: 1
  dist_url: "env://"
  distributed: True
